hi think line dependencyinformationreport.java needs fixed replacing could someone update please let know need additional information kind regards. hi documentation wikipediatokenizer specifically wondering pieces source xml get mapped field names solr schema example seems going date field example schema got goes body way get example thanks. using solrj programmatic way force course assumes able programmatically change location datadir another issue thanks. would parse html extract text first use index data nutch tika projects examples using html. hi ryan dug client code natural inclination would go latter fits better would write test use test request object. mitch right looking recommendation engine understand question properly yes mahout work though taste recommendation engine supports pretty new owen robin anil mahout action book early release via manning lots assuming list recommendations given user based past behavior recommendation engine could use adjust search results waiting jump best handle. ran minor problem clicked facet tried search would get error think problem fqs velocity macro vm_global_library.vm missing else insert url macro fqs p foreach p velocitycount else without url becomes /solr/browsefq=xxxx instead /solr/ completely new world velocity templating got low confidence right way fix. hi lurker interesting thread would suggest talking solr committers experience merging lucene got many similarities discussing though solr mature happened seen externally ultimately win though without lot teething issues many seemed personality conflicts groups versus technical/admin/operational issues additional comment inline ps counter example fine separate project solr releases eventually came faster lucene release cycle improved slow-down everyone expecting certainly reduced continuous painful debates belonged solr vs. lucene. believe code support handling form data sent put request logic make sure either unspecified application/x-www-form-urlencoded read body byte array use request convert string request unspecified assume us-ascii typically specified e.g use curl tool post data sent header convert key/value pairs using urldecoder.deccode string utf-0 since key/value pairs url-encoded believe standard assume us-ascii utf-0 would work well us-ascii viewed sub-set utf-0. two cases think cases two characters variant forms unicode tried unify still exist gb tons wanted support phonetic pinyin zhuyin search might collapse syllables commonly confused course would storing phonetic forms words. hi especially yonik http//replaced.url page mentions duplicate field collapsing later allow duplicate see mention deduplication happens search time normally requires field stored indexed efficiency might need fieldcache wondering status support thoughts potential thanks. hi james general immediate updating index continuous stream new content fast search results work opposition searcher isvarious caches getting continuously flushed avoid stale content easily kill performance issue interesting topics discussed lucene bof meeting apachecon alone wanting ways clear hard problem relax need immediate updates index accept level lag time receiving new content showing index would suggest splitting two processes backend system deals updates. code appears try maybe code date see /solr/conf used path code see created cwd/data data default specified work tried number different permutations maybe missed magic combination grepped source see pattern solr.solr.home used anywhere able control location config file using set location /data directory still gets created saw though seem use either see solr.datadir used code anywhere trying control command line seem work could uncomment edit tag file worked makes worried missing something wrong sources tell ways control location data directory used index a. change cwd sure inside resin b. edit tag file lets change directory ways control location config directory lets change directory thanks. got situation data directory needs live elsewhere besides inside solr home b moves different location updating indexes setting symlink /data great option best approach making work solrj low- level solution seems create solrcore instance specify data directory use update corecontainer wrong would like avoid mucking around low-level solrcore approaches thanks. hi robert -xx heapdumppath= something look versus gedankenexperiment. moving solr-dev solr-user quick impression given scope described page feels like boil ocean problem spent afternoon looking could use solr code getting much love somehow leveraging solr would seem like win three attributes solr interesting context complex query processing caching though critical things live noticed described issues automatic doc- server mapping calc stable hash quick exploration use hadoop rpc talk guts solr assumes query processing happens search server level versus master currently nutch way request summaries document via subsequent post-merge call master immediate problem ran notion solr running inside container currently penetrates deep bowels code even core level calls made extract query parameters url step going try clean manner would define side/solr core api layer would relatively easy least first cut hooking solr core nutch master via hadoop prc. hi michael build meant gui whereby user use special characters say quoting collection clauses programmatically build query without using query parser code wound write seemed like simple escaping quickly got complex convoluted e.g allow term get processed specially query parser ok case sounds like stuck escaping. hi ken given comments seemed describe using nrt opposite use case set solr use solr.mmapdirectoryfactory bother test whether nrt would better use case mostly sound like advantage focused things relating solr would love hear results someone testing batch indexing use case tested various xxxdirectoryfactory implementations please let know results testing. hi would thought queries would allow thing supported currently standard query would recommend re-posting lucene user list. general notice http//replaced.url uses solr search project data store index user-generated notes code finally went live last week openly post thanks solr community useful tool great. yes came exactly conclusion could try use ram jvm load index ramdirectory mmapdirectory wound slower configuration smaller jvm relied os-level cache make index accesses really fast trick heard /dev/null force index data. hi got fields contain embedded xml two questions relating appears though shall need xml-escape field data otherwise solr complains find start tag embedded tags finds tag field expected constraint xml-escaping data best way handle kind related question would easiest way ignore xml tag data indexing types xml-containing fields seems like could define new field e.g set associated tokenizer something new create though would un-escape data ick parsing skip tags thanks. hi uses solr generate terms mailing list text analysis extract good features things like classification similarity clustering last part cover using solr implement real-time similarity engine maybe recommendation engine well undoubtedly things unclear even incorrect please comment regards. ah yes would explain oddity saw order hits matching document boost since querying field omit norms really short. hi uses character separate elements e.g state|city solr 0.x worked fine query gets distributed across shards get solrexception severe org.apache.solr.common.solrexception use fieldcache field neither indexed doc values state problem appears fl= state|city parameter getting split functionqparser tries use state field actually exists ignored field since q=state|city ca| find entries california known issue way disable parsing field names field list thanks. actually tika htmlparser wraps tagsoup good option
