read storm-0 http//replaced.url question work hdfs state trident topology ensure record ends written hdfs states none. trident topology processes tuples opaque kafka spout three bolts write different forms processed output form different record parallelism rotation policy applied three outputs results two streams writing small files hdfs m thinking setting different parallelism outputs reason different parallelism settings across output bolts. trying understand relationship emitted transferred values spout trident topology multiple instances topology executing expected ratio emitted transferred would least similar instances topology differ quite bit example 0x another unit measured tuple tree storm topologies trident batch. thanks helps answer question batch fails could records batch get written disk hdfs state another. unfortunately wild card search terms get processed analyzers suggestion fairly common make sure lower case wild card search terms issuing query. use solrj dynamically created core capability know advance cores require almost always complete index build previous instance index needs available complete index build two cores index switch required indexing run issummary re early prototype implementation right production quality code tell voluminous methods identify core exists create method instantiates two solrserver objects solr indexcore requires create two cores indexname already exist live core used searching second core used indexing indexing two switched just-indexed core become live core way core works live core always named indexname indexing core always named indexname _index datadir core alternate indexname indexname create core already exists returns true new core created false otherwise solrj provides direct method check core exists getstatus index clearing first complete rebuild various logic submit batches could adjust core index complete reindexes need index always searchable hope helps. good answer may depend wanting restrict 000k documents seeking reduce time spent solr determining doc count wanting prevent people moving far result set case display digits return count solr performing adequately could always artificially restrict result set solr actually return 0m documents returns number specified query well cache next results anticipation subsequent query total count returned exceeds 000k report 000k number results similarly restrict far user page results sounds like sort results descending post date fact get recent ones coming back first. think client-id useful grouping quotas even secure clusters clienta user0 treated different client-id clienta user0 grouping clients user enables users allocate quota effectively clients guarantee critical event processing clients throttled auditing clients kip down-sized support user-based quotas hoping could extend later time enable hierarchical quotas understand confusing switch semantics quotas based modes set brokers let try promote original kip-0 time flag revert existing client-id behavior maintain compatibility perhaps necessary sound quotas may configured users sub-quotas may configured client-ids user quotas may configured client-ids users users don't quota override allocated configurable client-ids without sub-quota override share remainder user quota user quota limit default quotas may defined user sub-quota configuration client-id matches current quotas client-ids user quotas set authenticated users multi-user cluster currently possible define quotas client-ids multiple users longer supported. see changes kafka.common.kafkaexception socket server failed bind localhost:0 address already use java.net.bindexception address already use java.net.bindexception address already use went wrong run stacktrace option get stack trace run info debug option get log output. hey gwen yes approach much better described solves objections don't think mm rather original producer don't think adds overhead beyond additional header bytes i'm mistaken since mm already unpacks repacks messages unlike broker tries avoid repacking hence don't efficiently add header think objection around likely solvable kind aliasing scheme guys think made work think two pretty credible use cases tracing family uses plus number things least moderately improved i'm convinced. hi everyone feedback suggestions welcome thanks. hi pac0j vision direct clients ldap authentication example currently supported knox pac0j gateway two components authenticator validates credentials profilecreator create user profile default relies data returned authenticator means kind authentication assume two identity sources login get attributes currently supported knox pac0j gateway component client represents authentication mechanism done via identity source additional mechanism authorizationgenerator attach client compute authorizations login user profile retrieval fact could even use switch identifier user profile attribute thanks best regards jerome. basically test it's module run mvn -dmaven.surefire.debug -dtest= method-name test test wait debugger connect details. discussed comment. thanks himanshu done changes imposing restriction required weights side-effect couple test cases blowing restriction fixing xml it's post patch. nice another plugin moving forward. following comment added issue sure i'm looking forward thanks quick response. vote passed http//replaced.url replaced email.addr.es wrote. don't move makes easier build maven-plugins it's already installed. sure it's good idea i've found quite bugs related boxing projects example auto-unboxing field sometimes null may cause unexpected npe it's always obvious causing npe it's implicit code using integer using int vice versa remove explicit boxing usually many compiler warnings wade using suppresswarning auto-boxing justified work keeping explicit boxing/unboxing. thanks info refactoring imply api changes expect major changes alpha-0 sorry miss eclipse ever europe let know could don't meet eclipse summit europe eclipse project means license work never. could easily become problem example docker maven carlos maintaining bring in-project released maven project bundle jre maven project publishing could include jar known jsr-0 docker i'm sure annotations retained bytecode counts don't even started poor licensing classes jar least source headers x i'd need double check think x might bad. discussed couple lists already consensus projects i've involved issuing pull request github clear enough intent contribute long pull request properly forwarded right dev list think mailer setup ok several projects grabbing fixes via pull requests. hi i'd suggest use jira it's attached testcase part commit testcase small reflects problem well making part commit ensures 're fixing right issue. subscribed wiki page wiki category maven wiki change notification following page changed. new issue created jira. course. issues seems like days work quoted http//replaced.url quoted http//replaced.url. part still puzzles i've published new docs strange menu see don't match ii'm time work plugins page linked 0-alpha-0 archetype plugin docs many people still using make easy find sets documentation code published archetype project docs thanks raphael. actually proof concept don't finalised moment though possible probably avenue right check sources try thanks interest. cool thanks. 're going try cut release works 0.x would don't worry updating scm think users git likely m0 scm issues yes cut quick release 0.x users would try leave many existing deps alone. don't work snapshots iirc. following issue closed
