trying use archiva proxy maven central instance configured following configured local maven installation use repository see lot checksum validation failed issues warning could validate integrity download maybe use see archiva secure tls go directly maven central issues tried different combinations like maven central group using maven central group makes insane slow still validation errors manually download respective sha0 hash file see expected hash see maven suddenly think value start anyone ever seen anyone help kind regards. hi way group values like shopping.yahoo.com shopper.cnet.com instance documents like i'd like result grouping product value range product something like like current facet information grouped item entire result idea thanks. performance difference using fields defined schema vs dynamic fields. case getting results stop word issue. top shawn rightly said two things try benchmark best bet solution without shingles know better story numbers tell go shingles approach consider removing duplicates. chromosome gene object types really boils able give number e.g return documents regions containing number i'd document list like look build features using spatial believe david covered usecase talk san diego get error able find abstractsubtypefieldtype first bit trace hints wrong provide source code fuller stack trace config settings etc try unpack solr.war stick jar web-inf/lib repack however get noclassdeffounderror plugin fuller stack trace might help key question order try two approaches exactly fieldtype declaration look like tried repacking first maybe exploded still polluted old jar repacked multiple copies plugin initial noclassdeffounderror could try starting competley clean using stock sample configs make sure get errors try declaring custom fieldtype using hte fully qualified w/o even telling solr jar ensure get noclassdeffounderror custom get error abstractsubtypefieldtype still directive load jar load still wouldn't work provide us details container solr version full stack trace details configuring declared filesystem looks like solrhome etc. thanks sorry wouldn't really solr-related monitor wouldn't rely output free command think could still achieve significant improvements going performance tuning advice wiki. see http//replaced.url basically list special characters text file types attribute map alpha. hi trying implement auto suggest functionality currently looking terms component solr example form query like searches field strings starting results could possible get info results component like return data fields example along results field corresponding data telephone field maybe simply execute normal wildcard search thanks. thanks exactly every incoming query via entry custom requesthandler thus question reference original query text requesthandler xml believe i'm going use simpleparams syntax yes ideally would simple requesthandler would recognize q magic variable holds current search text came q url i'm guessing wouldn't access query requesthandler without inside brackets simpleparams like however pointed alternatives believe i've found easier way least case think ensures standard search catchall field text happen boosting additional search occur boost listed thanks caveat boosting function i'll set expectations users wouldn't limit search docs figo could guarantee show boost seems best compromise unless parse search results code i'd rather avoid whenever possible. displayname displayphone even schema print solrdocument object directly see results. able read indexes produced way back including 0.x sometimes experimental formats excepted case fine since you're upgrading always though i'd recommend copying indexes someplace paranoid upgrading best. different solution need i'm measuring response times different collections measuring online/batch queries apart using new relic i've added filter analyses request makes info available new relic request argument built new relic solr plug wouldn't provide much. thank. continuing fight keep solr setup functioning result made significant changes schema reduce amount data write setup new cluster data initially ran import replicas achieved quite impressive results peak new documents minute shard loses outages due garbage collection issue see production load index stood documents 00gb shard highest insertion rate would say querying suffered concern right added replica shard indexing time doubled surprising good start problem continue write leaders issue replicas continually going recovery leaders show ioexception occured talking server replica busy garbage collecting wouldn't coincide full gc collection times low replica appears accepting adds milliseconds appears log org.apache.solr.handler.admin.coreadminhandler requested recover reduced load documents minute appear stay couple minutes would like confident could handle peak times initially getting connection reset errors leaders changed jetty connector nio message received upped header request response ideas using replicas proposed colleague thanks much advance. hello shawn thanks reply look asap know dev environments persistent flag set true i'll check others production see someone get copy logs production environment see detail contained within thanks. ahhhh it's lightbulb last paragraph cleared confusion carrying responses incidentally likely reason confusion zk question could wouldn't make sense thinking zookeeper separate means handling things solrcloud two entirely different approaches scaling much helpful see balance assumption thanks shawn-. detailed perhaps alphabetical hierarchical table contents ether wikis sole site sent mail android. demonstration feature would good addition example/multicore directory. hello index fields dynamically wouldn't suit need wouldn't know fields advance fields must set dynamically need strong typage think solution handle programmatically best way custom handler api use. using example stack trace looks like error finding solr.home index directory configured example schema.xml works try adding little bit schema time. yup definitely need address make next release accumulo. hi thanks interest gave wiki permission. you're right patch updated catch exact exception thanks comments. hi thanks review updated following things latest patch check server starts successfully sqoop0 server started don't displayed remove file stopping server bug updated good suggestion get server status check file exist exist validate add checks environment variables hadoop lib related set start server wait seconds check result exceptions sqoop0 server started don't displayed. reworking break renderer source file might revisit elements embedded html elements renderering i'll let pass text. build stop unsatisfied dependencies currently functionality behave well maven jar override feature fixing first step toward stopping build continue failed dependencies attempt download still failed dependencies tried satisfy dependencies problem might problem use remote repository create message user stating dependencies unsatisfied. hi devs i'm getting following exception starting tomcat server airavata rc0 deployed idea resolve configuration add credential-store/client.xml able start tomcat without issues first time error comes try start tomcat server second time regards. think data blocks written dfs created index blocks think buffered written groups rfile operations scan index fast read lots index blocks sprinkled file groups contiguous index blocks read quickly sent phone please excuse typos brevity. eric looked locality running continuous ingest found tablets local data matches expectations default balancer try migrate child split sibling tserver concept may complex implement sigh cool. hi sorry missed respond earlier please see good comparison need make sure relevant jsdl semantics covered debated add field early compared saga jsdl rsl api it's like moab web services could conclusively narrow three parameters include problem including three could contradict making validation tricky think need select two three three confuse usage may kenneth opinion current app catalog design interfaces deployment decoupled parallel environment described application deployment question user specify particular parallel environment currently implicitly done picking right deployment could re-think allow users/gateway select deployment based parallelism reverses current approach timely actively revisiting data models keep mind get back http//replaced.url. hi network plugin implementation question i'd like extend bigswitch networking plugin firewall service plugin element implement firewallserviceprovider interface well included 'local notation rebuilding management server still see plugin showing firewall provider drop menu adding network offering network guru help point might missed thanks. tried without files trying import backup new dont know revision main site gui theres http error smthing information try command line admin.sh -i last thing says value org.simpleframework.xml.element name= data=true required=true org.apache.openmeetings.persistence.beans.domain.organisation.name seem like backup right first place tell tries find doesnt thanks advance
