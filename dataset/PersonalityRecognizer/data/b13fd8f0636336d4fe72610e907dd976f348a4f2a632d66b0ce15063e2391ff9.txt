hello everyone hope email finds well hope everyone excited apachecon would like remind couple important dates well ask assistance spreading word please use social media platform get word visibility better apachecon link main site found http//replaced.url planning attend apachecon north america may add-on option registration form join conference discounted fee us available apache big data north america attendees please tweet away look forward seeing vancouver groovy day. ago similar issue least back think possible use solr iscopy-field support create boosted version field copied field multiple times. hi frederik figure solution problem asking recently ran similar problem similar setup shards server occasionally query long time occasionally see timeout exceptions http requests e.g restarting jetty seems clear problem temporarily looking code solr handles distributed requests got interesting smells would surprised issue related using regards. hi frederik directly run issue solr experienced similar issues related context case custom made solrj requests generated aggregated/analyzed results load testing ran different issues load test software issue scaling assuming case seen happen e.g limit max parallel connections client used talk solr needed tune solrj settings httpconnectionmanager heavy load running free connections given got shards request going spawn http connections know top head manages connections whether possible tune stack trace sure looks like blocked getting free http connections needed optimize configuration jetty jvm gc etc lots knobs twiddle better worse. think need create separate background process least case web crawling challenge efficiently use samza process simultaneously fetch many urls increase complexity process iscode wind manage either multi-threaded async fetch state hadoop-based crawlers limited number parallel reduce tasks fetching see nutch bixo examples e.g fetchbuffer another project involved past. hi running problem queries distributed among multiple shards return binary field data properly hit single core xml response http request contains expected data hit request handler configured distribute request shards xml contains b b looks like wind getting .tostring data actual data anybody else run done fair amount searching hits yet next step create unit test solr nobody raises hand walk thanks. general yes subset terms occur frequently remove terms easy longer search either part query phrase combine common terms following terms works well bit complex significantly grow index either requires data analysis generate target set common terms. area might issues date range queries many docs run oom errors recent thread yonik others good suggestions ways avoid problem know impact would merging results use date ranges guessing low yonik would know best well 0-server configuration would work would 000m docs/server large number even data/doc small 0k real performance going heavily impacted nature data types queries shall need think distribute data avoid performance constrained worst case searchers nutch wound add termination logic avoid long-running queries clog things primarily dealing load best first step create single solr representative data see well performs issues going around limits box 000m docs versus distributed nature though keeping servers alive happy significant ops task finally would decide early whether search query words ok result set happens missing doc server timed looking query-type solution solr would less interesting. csvloader user found/fixed bug involved active development/maintenance piece code james make progress merging support csv dih great. merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. thrift framework providing cross-platform rpc serialization thrift community continues see consistent growth increase new contributors since recent release resolved almost tickets working towards milestone release apache thrift pmc voted switch svn git primary management website svn repo updated links new repository seeing overwhelming positive response change. sorry realize thrift moved git forked mirror github submitted pull request http//replaced.url however original patch applied without conflicts compiled without warnings show last git commit 0a0c00a svn revision r0000000 give information equivalent without flush attached patch accomplishes minimizing code churn removing using namespace std introducing static variable endl. pr developer able debug issues dependency resolution easier pr tested breaking changes older versions merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. thanks sharing work checked code looks interesting please free create issue/pr don't mind thanks. updates make interpreter updated language zeppelin interpreter separate jvm process default updated make interpreter configure interpreter better explain process merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. goal community merge point two different r interpreters another still trying wrap head around difference. first would like introduce pedro toribio responsible product development sofia0 indra http//replaced.url evaluating use zeppelin entry point information sofia0 need develop zeppelin interpreter use sofia0 i've run problem able debug interpreter debug zeppelin-server dependencies remote interpreter runs remoteinterpreterserver lose control consequently debug interpreter 're done address development interpreter reason post indiqueis us whether possible debug interpreter running platform carried http//replaced.url replaced email.addr.es minsait.com. 0ambda thanks effort tested works well expected maybe it's nit colors different. pr pr tested breaking changes older versions merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. pr spark default value it'spark.executor.memory 0g 000m let it's follow change pr x replaced occurrences default value spark.executor.memory '0g' tested checked people it's eyes breaking changes older versions needs documentation merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. separate job manager notebook server good large amount duplicated code introduce maintenance overhead best extract common code make notebook server job manager server share. hi heiko it's really great hear interpreter prestodb think issue discussion presto db far please feel free create new issue best. hi cooperating frank seidinger j0me plugin need set bootclasspath compiler plugin done pom like however use unified emulator interface determine bootclasspath automatically configure compiler accordingly able access uei know access current container evaluator least test harness creates container uses stub evaluator get container running maven instance evaluator pass configurecomponent alternative frank proposes introduce wireless toolkits plexus compiler level find information would appropriate point view regards. able reproduce blueprint tests camel testing fix likely need respin build thanks finding. cxf contains several new features complete list changes required migrate cxf see addition apache cxf community released patch releases contain several fixes bugs issues users encountered downloads available information see feedback questions would like get involved cxf project please join mailing lists let us know thoughts. it's race condition evidenced lines /var/lib/cassandra/data/system/locationinfo-e-0-index.db file deleted file tried read create ticket. center point query circle indexed point query radius matched plugged numbers perhaps misled projection using view map far away points fyi default disterrpct fine general don't issue almost never use field means indexed non-point shapes rectangles said use indexed terms unless small rectangles relative grid resolution meter case using disterrpct=0 query safe hand. hi must supply dates format iso-0 indicate time-zone offset occurring reduce cardinality day level instead second currently performing date supply include datemathparser operations supply 0:0:00z/day think course loose ability search based granularity finer day date get back i.e stored value rounded date date prior rounding yes certainly need re-index since architected indexing strategy know go i'm sure aware update individual fields way current strategy involves periodic updates could strategy simply waiting data eventually gets re-indexed it's harm dates rounded it's rounded current problem sporadic oom. hi hoping get answer geospatial topic links basically confirm approach wanted work ok similar even bigger amount data plan instead good enough quicker implement
