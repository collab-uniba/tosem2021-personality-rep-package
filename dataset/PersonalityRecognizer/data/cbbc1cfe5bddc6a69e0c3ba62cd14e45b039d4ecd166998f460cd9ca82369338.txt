newbie solr done everything solr tutorial section using latest versions jdk solr see solr admin page http//replaced.url hit search button receive http error tried run solr tomcat unsuccessful solutions document links appreciated thanks help. trying overlook expected i'manilow get response though wow geoff wouldn't know musician well like gogh it's birthday two days ago names famous artists would spirit use unusual color names simpsons theme maybe oughtta stay away homer d'oh could self-referential tapestry know you're wikipedia many projects use release release number think tapestry start road map im-ing erik brainstorming theme liked city names chose favorite cities single word names portland vancouver boston amsterdam etc it's possible roadmap methods/classes probably sensible naming etc. like unless i've completely base hardest part new liberal allowances template location i'm deliberately avoiding assuming resolved handling anonymous components actually fun i'm figuring way spindle represent anon comps way able following mixed spec comp/anon comp edit bindings anon comps spec editor changes pushed pull anonymous comp template insert spec naming template component truly anonymous push spec comp template make implict/anonymous need improve validation/error handling include definitions sources brings another point would hard change tapestry parser make easy extend following possible would cool 'fatal-ness error configurable would useful spindle could set switch something parse would go completion unless true fatal error like well-formed occurred mechanism collect errors create error markers thus example validation error markers validation problems first course error occur would ignore parsers result object would nice get line/column info errors generated tapestry code probably harder last list support last thinking adding page spec editor contains template source would hardest thing accomplish much harder finally wiki page template directive indicate page it's format directive. resources defined dojo it's css served. hi edwin changes recommend bin/solr.cmd make easier work nssm please file jira i'd like help make process easier thanks. it's call release manager binding technically vote passed. shell gets it's memory config accumulo-env file accumulo_other_opts reason value low lot data loaded tab completion stuff shell could try upping value file try running shell disable-tab-completion see helps. thanks eric wouldn't cleaning something hadoop-data directory zookeeper. hi i've read source code documentation following iterator commonly used batchscanner accumuloinputformat parallelize search shardids means key0 key0 shradids searched misunderstanding indexeddociterator search shradids thanks regards. right got change maxversions many times wouldn't persisted disk compaction rewrites data scans however always consistent current configuration implementation accumulo instantiate current iterators minc majc scope depending it's minor major compaction write output memory/files compacted filtered/transformed iterators back single file. thanks calling principle community code super important matter code kafka project could simply pull samza code write new stream processor without asking permission would don't get samza community thus think community aspect important part discussion 're talking merging projects it's really merging communities chat friend lucene/solr committer originally two separate projects merged said merge always easy probably net win projects communities overall community people tend specialise either lucene part solr part it's ok it's still cohesive community nevertheless benefits close collaboration due everyone project releases don't slow fact perhaps got faster due less cross-project coordination overhead allayed concerns big project becoming slow besides community code/architecture another consideration user base including mailing list good users i've thought last days reducing users confusion good someone adopting kafka need way processing data kafka moment kafka docs give consumer apis nothing choose separate stream processing framework burden users especially framework uses terminology inconsistent kafka make samza part kafka unify terminology would become coherent part documentation much less confusing users making easy users get started good simplifying api configuration part making yarn optional good would help part package people download part documentation simplifying api/config decoupling yarn done separate project becoming part package would require merging projects supporting users choice programming language good used work ruby ruby community plenty people irrational hatred jvm imagine language communities likely similar samza becomes fairly thin client library kafka using partition assignment etc provided kafka brokers becomes much feasible implement interface languages giving true multi-language support thought coming conclusion stream processor part kafka project would good users thus successful project however people experience stream processing systems samza community leads thinking merging projects communities might good idea union experience communities probably build better system better users jakob advocated maintaining support sources kafka totally see need framework think need pretty well satisfied storm already spouts kafka kestrel jms amqp redis beanstalkd perhaps don't see much value samza attempting catch especially copycat provide connectors many systems different means hand failed attempts implement systemconsumers kinesis postgres make think stream processor supports many different limited lowest-common-denominator model samza supports kafka think could support kafka better framework thing well sure understand point departing vision distributed processing library-ified samza would still allow distributed processing small amount glue could still deployed yarn cluster conclusion i'm starting agree approach jay advocating thread. hello using hdfswriter provided samza package samza-hdfs try write newest patches version bug regarding closing files fixed bucketer seem work given every new event sent hdfs outputstream system creating new file hdfs according taken appending events existing file bytes threshold reached known bug missed sth implementation kind regards. jay yes current function jobcoordinator partition management maybe call partitionmanager make. auto scaling module package org.apache.samza.autoscaling.deployer however whole auto scaling samza-core problem. rather relying external stream hello samza example perhaps look something local option would simulate/fake data may bit boring real data could look local box treating hardware resources/dmesg/proc files stream writing little samza job summarizes/processes data pretty nix focused though minus. rebase yesterday realized something git refused add files right it's missing couple files going address comments add files update rb sorry confusion. i've put patch get samza working yarn. hi assuming using configurations set systems.system-name.streams.stream-name.samza.reset.offset true systems.system-name.streams.stream-name.samza.offset.default oldest see hope helps thanks replaced email.addr.es. try reply-all request dc-allow address add rb subscriber regards. chime i'd interested monitoring blog post 're kafka implementation robust data pipeline initially samza look interesting monitoring use-cases replaced email.addr.es wrote. request incorporate sure best way bring kindly let know formal way propose apache forum apache kafka team format discussing new topics via kafka improvement proposals provides meeting members read topic proposals hangout/ meeting consider. heartsavior would like look it's similar pr put. release based clojure 0.x code migrating apis org.apache.storm big non-backwards compatible move major version bump 0.x seems like good move would like move user facing apis org.apache last things translating clojure code java moving org.apache concerned two code bases diverged significantly another terms functionality storm code soon heartbeat server nimbus different implementation resource aware scheduling distributed cache like api log searching security massive performance improvements shaded almost dependencies rest api programtically accessing everything ui sure missing things jstorm many changes including cgroup isolation restructured zookeeper layout isolation matter large effort port changes code base another clojure java proposed initially broken incremental changes may little longer always working codebase testable compatible current storm release least move user facing apis org.apache lets community continue build test master branch report problems find incredibly valuable personally don't think much easier especially intent always maintaining compatibility storm bobby thanks merge plan question phase mean community plan create fresh new java core based current clojure core firstly migrate features jstorm confused really huge job might require long developing time make stable jstorm already stable version release planned release nov 00th already run stably several month alibaba besides many valuable internal requirements alibaba fast evolution jstorm forseeable next months java core totally fresh new might bring many problems coming merge point view think much better easier migrate features clojure core basing jstorm java core please correct misunderstanding regards based number discussions regarding merging jstorm code i've tried distill ideas presented inserted result i've divided plan three phases though necessarily sequential obviously tasks place parallel none set stone presented discussion comments welcome
