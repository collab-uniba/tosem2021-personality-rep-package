documentation http//replaced.url specify names/positions fields csv file ignore fieldnames seems like would solve requirement different layout could specify mapping import could handy provide map versus value map updatecsv supports could use header provide mapping header fieldnames schema fieldnames. hi would started using embedded solr back via patched version in-progress code base wondered paragraph said given current state solrj expected roadmap solr general would guidelines special circumstances warrant use solrj know back namely multiple indexes run multiple webapps handled multi-core generating lots http traffic handled dih maybe solr search system since integrated system hands customers restart container option anything got wedged might still issue commonly compelling reasons use solrj thanks. hi arno need add boilerpipecontenthandler tika iscontent pretty sure means would need modify solr e.g trunk tikaentityprocessor.gethtmlhandler method would try something like return new boilerpipecontenthandler new contenthandlerdecorator though quick look code curious use. hi exactly something similar nutch searches using ehcache http//replaced.url store rewritten query string serialized xml response way dependencies stable searcher/doc ids nutch reference get remote searchers depending entries cache hit docs xml representation storing xml might. hi savannah comments scattered in-line store xpath expressions text file strings load/compile needed definitely yes using tagsoup clean bad html definitely yes needing per-site rules typically xpath optional regex needed extract specific details common sites powered back-end often re-use general rules markup consistent kind thing use bixo http//replaced.url requires knowledge cascading hadoop order yes would separate job field index though often job titles slight variants would probably work much better automatically found common phrases used otherwise get senior bottlewasher sr. actual format extension b characters xml posted. normally would say like getting swap based settings 0gb jvm space used 00gb box confirm nothing else using lots memory right top command showing swap usage right encounter slow search times top command say system load cpu vs. i/o percentages. hi sandhya would post question replaced email.addr.es mailing list include details document confidence level often low enough tika assume good match thus report language. hi erik let us say grins different field besides used autocompletion would places would need hit change field besides terms.fl value layout.vm example asking trying use latest support index uses product_name auto-complete field getting auto-completes happening see solr logs requests made /solr/terms auto-complete look like would expect work seem generating results odd try curling thing use would consider minimum set parameters get expected xml response ideas wrong thanks. curious mean utf-0 complaint mean thanks. interested need sorted output faceted browsing alternative output formats something along lines merge xml responses w/o schema proposal would fine much better would use hadoop prc versus http call sub-searchers assuming better performance might fewer connectivity issues leveraging work done embedded jetty example anybody data points relative performance master schema main search server could get distributed remote searchers would part thanks. hi trying morelikethis support getting odd results realized unless fields used similarity lucene re-analyze field using standardanalyzer case quite different using solr schema first note anybody using morelikethis make sure specify termvectors=true solr schema fields passed query mlt.fl parameters second note wiki page example schema might include reference termvectors field attribute example sample schema says made think initially attributes http//replaced.url make mention termvectors termpositions would edit page currently section talks attributes common ones thanks. shamed taking position vote earlier real experience slf0j indirectly via use jetty know would _something_ logging hood use log0j everywhere finishing earlier work creating jul logger bridged log0j another option would rather avoid. hi got field defined solr schema always contains two fixed values documents get added boost supplied varies max query field expecting ordering results would match boost values longer specifying omitnorms= true field still get seemingly random results use full search interface solr results two documents different boosts looks like expecting value different different document boost values missing thanks. currently links seem wind pointing api-0_0_0-alpha versions expected e.g search streamingupdatesolrserver first hit streamingupdatesolrserver solr api follow link get page http//replaced.url. difference free speech free beer see http//replaced.url. think concern could addressed set defaults fall back try following sources order get value found try contextroot namespace-specific property found pom.artifactid think plugin always able override project-level value first common system property like contextroot would allow multiple plugins configured property finally currently default. preparing patch submission maven-eclipse plugin fix bug enhance functionality setting context-root wtp0.0 project question pom.xml user specify right wtpcomponentwriter grabs webappsrc value maven plugin seems like logical place put contextpath/contextroot parameter time probably appropriate put property used plugin otherwise property could go eclipse plugin configuration feels bit odd reason. wiki page show use -h option curl set see. yeah terms expand phrases use wildcard fuzzy queries special characters slash part term try. uniquekey wiki recently updated indicate new solr solr field must populated via changes given contained updated wiki page. agree it's bad situation don't handled well lucene guys may good reasons don't execute decent plan migrate existing behavior. particular reason use see give bunch examples book. annotations jar breaks tapestry running jdk numbervalidator allow special case rendering zero used assetservice copy private assets onto file system within web folder static urls assets may generated may use file except compliance license may obtain copy license stored normally visible client web specifying two configuration values tapestry export private assets directory visible client web browser url value map directory specified value due changes tapestry longer needed issues security performance fixed tapestry allowing private assets accessed zero configuration. must archiva-0.x branch removed cant kept. thanks sharing experiences vaclav it's valuable yes bad things happen region server don't phoenix jar improved hbase hbase-0 hbase-0 fixed phoenix phoenix-0 chance would mind filing jira much detail thanks. ah don't notice timeouts shown final report failures seems build using jdk test run oom thanks. you're using avatica context phoenix might interested phoenix-0 adding load balancer phoenix query thanks. behalf apache sqoop pmc excited welcome venkat ranganathan new sqoop pmc member venkat ranganathan become committer last year since remain active project helping reviews user questions working various features recently added support hcatalog/hive added support lot new data types requested users see quite impressive list contributions well deserved venkat
