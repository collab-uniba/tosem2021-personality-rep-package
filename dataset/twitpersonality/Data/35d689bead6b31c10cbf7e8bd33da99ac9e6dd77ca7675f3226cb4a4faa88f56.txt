hello quite new solr trying get grip currently reading enjoying solr enterprise search server book trying failing need advise following given following schema subscriptions would like group accountid facet isclosed accountid addition would like see number created subscriptions since given date would possible figure grouping something like advise would highly appreciated regards. ok shall try answer would correct give data need indent=on f.createddate.facet.date.start=now/days-0months f.createddate.facet.date.end=now. yes see question bit confusing thanks answers try clarify bit query date field validtodate value field present documents would like get number documents given date range r0 value validtodate i.e documents number documents given date range r0 value validtodate question really possible query need two queries facet.range.other=all help way. hello following faceting parameters gives unwanted non-null dates result set way query index give non-null dates return i.e would like get result set contains non-nulls validtodate faceting non-null values validtodate would like get non-null values faceting result response example gives results non-null validtodates would like get results non-null validtodate facets write start wonder possible facets dependent result set might better handle application layer extracting help would appreciated. hi moving towards embedding multiple solr cores versus using multiple solr webapps way simplifying build/deploy getting control startup/update process would hate lose handy gui inspecting schema importantly trying queries explain turned anybody tried dual-mode method operation thoughts whether workable issues would taken quick look supporting java code ideas would needed hoping easy approach whacking admin support code thanks. well ultimately heading towards single multiple embedded solr cores case could .jsp-based gui/admin functionality peacefully co-exist use embedded cores description roadmap solr gui example assuming files still exist going forward become much gui layer top new/beefed plan eventually get html using json responses request handlers thanks. hi have got ancient lucene tokenizer code m trying avoid forward-porting not think isequivalent solr specifically isapplying shingles output something like worddelimiterfilter e.g mysupersink gets split super sink shingled re using shingle mysuper super supersink sink not follow wdf single filter shingles not created across terms coming wdf ispieces generated wdf actually way make work solr thanks. hi renee mike right question post users list yes separate setconnectiontimeout used though familiar possibility ping response handler responding connection established getting data back. turn facets query facet=true facet.field= shall get back distinct values though might play settings e.g facet.limit=0 get results need. hi yonik ah explains little seen resin parameter used inside init method typically specified using tag know resin-specific yes would easier update resin runs unpack .war kind pain way knew get working versus jindi approach got special reason ask ongoing support init-param technique. available cores dynamic cores requirement custom code wasted. hi feel like must missing something working customized version supports distributed searching multiple local cores assuming support searchcomponents handler needs create/maintain responsebuilder passed various methods responsebuilder finished list shardrequest objects requests received responses shards inside shardrequest responses list shardresponse objects contain things like solrresponse solrresponse field shardresponse private method set package private appear like easy way create shardresponse objects searchcomponents expect receive inside responsebuilder put custom package shardresponse call setsolrresponse builds run locally deploy jar code runtime get illegal access exception running jetty make work re-building solr.war custom pretty painful thanks. way mean configuring current extractingrequesthandler fundamental issue solr uses tika prevents extractingrequesthandler modified work way seems like useful configuration regards. hi would copied/pasted schema fields testbed schema based version solr using back dark ages version handy comment warning changing version fields multivalued default would checked docs realize behavior changed days would used http//replaced.url examine field would seen thanks. useful use morelikethis support see http//replaced.url attached patch. receive documents day various sizes documents could pertain contacts stored database could include file maintain list contacts related involved file know never exact i'd like index possible names text attempt identify files document might pertain looking files tied contacts contained document i've found regex code parse names text anyone ideas set index currently approximately documents library. really don't like giving unhelpful responses like don't think it's way go solr-user mailing list end-users regulars including little experience lucene even though solr lucene application source code number lucene-specific discussion places available thanks. hello writing xml hand xml writer cause problems exception says latitude converted think use java0 unfortunatly stream writer filter invalid xml characters point helpful website hope helps. search engine groups text give users ability search ability conjunction selection searching conjunction means user able search fields fields i'm realizing give ability search everywhere archieved copyfields parameter user search bunch terms different groups i'm using syntax give oportunity search fields ability specify field0 field0 term view message context http//replaced.url sent solr user mailing list archive nabble.com. unique it's index added worked mentioned requirement distributed search thanks jaikit set cores single collection schema different index set unique required field false run query single core works fine add shard param point different core request fails npe looked source code querycomponent line isresultids.put sharddoc.id.tostring sharddoc looks like sharddoc id.tostring throwing npe.http //grepcode.com/file/repo0.maven.org/maven0/org.apache.solr/solr-core/0.0/org/apache/solr/handler/component/querycomponent.java querycomponent.mergeids 00org.apache.solr.handler.component.responsebuilder 0corg.apache.solr.handler.component.shardrequest clue set incorrect appreciate pointers thanks jaikit. wanted eliminate administration core web site could eliminate either solr.xml remove solr.xml file mentioned page manipulation example adminpath= /admin/cores configures access via http//replaced.url attribute specified dynamic manipulation unavailable. thanks erik reply know it'set it's goal give better example add another list_c look like however add list_a reindexing documents depends goal i'm guessing 're using atomic updates case need use set rather add former replaces contents see http//replaced.url 're simply re-indexing documents send entire fresh document solr i'll replace earlier document best. two databases unfortunately separate get imported solr database primary key time concerned comes importing two solr item db therefore order keep two separate databases two different uniqueids wondering kind options append letter primary key db even possible. bet it's point covers believe it's simply thread-local hashmap nothing stored loggers code using need careful remove variable mdc 're done. mandatory. yes don't need either don't need scoring. try looking logs lucidimagination.com
