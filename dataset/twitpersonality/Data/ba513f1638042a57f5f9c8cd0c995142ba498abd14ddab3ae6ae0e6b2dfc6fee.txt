p.s volunteer help kip sent protonmail http//replaced.url encrypted email based switzerland. karsten said providing detail actually trying usually makes better helpful/accurate answers guessing search key value right create multi-value field custom indexed stored indexing add entries custom set analyzer strip index key e.g. would first try setting post explicitly utf-0 matter appears resin tomcat issues properly handling form data without matter issue configuring tomcat see http//replaced.url patch applied may 0th year work around appears bug tomcat assume version solr patch. hi sorry noise finally realized running using java code enwikicontentsource lucene benchmark explicitly set fields push results solr. use characterencodingutf0 think shall get back stream utf-0 bytes db know mysqlxmlfield isstart array bytes returned jdbc call create string array using utf-0 encoding use bytes directly writing xml best thing make sure xml send solr starts line make sure converted text xml fields wrap fields. hi low query rates using shards approach improve performance multi-core cpus solr cores setup distributing requests effectively use cpu cores parallel request spread shards across spindles maximizing i/o throughput issues approach binary fields work results back b versus actual data short fields get java.lang.short text prefixed every value deep queries result lots extra load e.g 0000th hit shall get shards hits collected/returned dispatcher though unique score returned case followed second request get actual top hits shards something wonky way distributed http requests queued processed load see ioexceptions always n-0 shards succeed shard request fails good reproducible case yet debug. general issue months ago generate reports things like scm commit activity given day larger customers users multiple timezones timezone use wrote blog post http//replaced.url short answer ultimately decided use utc times server report api ui least heinous various options. hi encoding using pushing documents solr specified xml post request separate issue mime-type use post using latest scripts solr characters look like xml pushing example encoded two surrogate characters instead code point extension b set xml parsers handle correctly source similar issues seen potential issue xml parser used updated handle extended unicode code points older parsers still failed handle example. hi tommaso slaves configured use vip talk master easy dynamically change master use via updates. related item might check jmaki http//replaced.url jsp-based amount jsp-generated content pretty easy add support dynamic. hi working project speak stefan friends going live separately something independent solr/nutch view search plumbing usable multiple environments makes sense view replicating core solr nutch functionality sucks sure outcome. error either schema.xml file messed might still need uncomment lines beginning file ones say uncomment trying use resin version even though using later version resin lots issues xml parsing. confused answer assuming based page referenced url provided approach textprofilesignature would generate different md0 hash single letter change change resulted change quantized frequency word uncommon word would even show signature. low qps multi-core servers believe reason multiple shards server provide better parallelism request thus reduce response time. idea thought given document/field set would contain text single language write special token language e.g analyzer add my-special-token-prefix-esperanto token field query time assuming know language make required term. depending complexity solrj could solution see section talks solrj provides apis create. would use data files. hi list working improving performance solr scheme cascading supports generating solr index output hadoop job use solrj write index locally via embeddedsolrserver mentions using overwrite=false csv request handler way improving performance see http//replaced.url removed support solrj deemed dangerous mere mortals question whether anyone knows much performance boost really provides hadoop-based workflows straightforward ensure unique key field really unique thus performance gain significant might look figuring way trigger lock re-enabling support solrj thanks. hi especially yonik grins trying solr resin following copied solr-nightly.war /webapps/ cloned/edited resin.conf file include mapping solr adding started resin created /webapps/solr-nightly directory expected tried use solr complained finding see stack trace email realized solrconf folder included default .war added inside /webapps/solr-nightly directory result tried moving uncommented lines file yonik indicated necessary get resin work properly solr change anything figured would ask correct way configure solr resin rather continue thrash would help resin jock far usage limited futzing resin config file add simple thanks. sort answering question seems like need get current core use instantiate new solrcore exact config documentation solrcore isconstructor says core already exists stopped replaced unclear whether graceful swap like hard shutdown old core thanks hoping somebody clarify coredescriptor since much documentation far tell create new solrcore saves coredescriptor pass nothing constructor solrcore takes datadir param see coredescriptor isdatadir gets used construction changing coredescriptor isdatadir effect since would go changing datadir core multi- thanks. right baking fine-grained level security information bad idea example worked pretty well code search krugle project number groups granted access rights file project would inherit list groups user logs get authenticated via ldap set groups belong returned ldap server becomes fairly well-bounded list terms query acl-groups field file/project document set boost portion query. large index would recommend separate solr installation use update/commit changes use snappuller equivalent swap live search unlikely switch lucene tune new parameters control memory usage updating. believe mistake recent email thread list. based experience using jira manner would agree mike automatically assign fix go path wind steadily growing wave deferred issues constantly getting pushed next. patch handles case corruptrecordexception thrown iterator directly merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. behaviour-change enabling enter-keypress saving values sweet possible reject changes 'esc. ready review latest ignite release published next day merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. put time reading rfc yes actually went code latest changes lgtm think last terbolous comment sent remibergsma made change checks pub ip within range reserved rfc. pr fixes issue doubled new lines lines converting jupyter notes zeppelin note pr tested run 'java -cp zeppelin-jupyter/target/zeppelin-jupyter-0.0-snapshot.jar org.apache.zeppelin.jupyter.jupyterutil -i path/to/ .ipynb produce 'note.json' import 'note.json zeppelin don't doubled spaces breaking changes older versions needs documentation merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message. generally big changes touch multiple spark cassandra angular etc hard review forever get merged need consensus maintainers parts would suggest pr separated least improved reviewed fast independently. could please check make check runs test suite. added couple comments think 're ready merge hostname changes comment yet cluster changes note knowledge setting hostname based experience past it's possible modern distributions things differently perhaps recommendations changed nevertheless way still work. merge pull request git repository running alternatively review apply changes patch close pull request make commit master/trunk branch least following commit message
