hi still problem projectbuilder followed api change projectbuildingrequest see following setup gist problematic code works version beta-0 gets npe version beta-0 later hints welcome better regards kristian. plugin use maven0 api maven-beta-0 gives maven-rc0 gives maybe used projectbuilder maybe part public api maybe writing plugin regards kristian. trying understand various options worddelimiterfilterfactory tried setting options seems prevent number words output particular wouldn't 00dxl wouldn't get output wods containing hypens correct behavior solr analyzer output schema. hi you're trying push security related info index control users search certain fields you're wondering best way accomplish records indexed searched certain fields marked private field marked private querying users see/search whereas super users it's solutions you're considering index separate boolean value new _internal field indicate corresponding field value marked private include filter query searching user super user eg. consider record contain fields field000 field0 field0 marked private field0 record field0 marked private record b field0 index records it's i'd index searching user super user query let it's say security needs look like this- field0_internal:0 field0 security field0 security manipulating query way seems painful error prone we're wondering solr provides anything box would help determine fields query depending visibility using example it's indexed records would look like searching user super user query needs regular fields whereas searching user super user query needs regular internal fields issue solution since number docs include internal fields going much fewer you're wondering relevancy would messed you're querying regular internal fields thanks. particular reason would limit documents facet calculation mean whole point facet numbers let users know it's must rationale mind. personally i'd stick solr it's built-in dynamic field definitions keep things smooth future developers ease matching i'll see list via support channels use field aliasing know dynamic field fl=price price_f sort thing client deal friendlier names wouldn't think reasons best practices dynamic field naming conventions personally i'd use _/underscore separator though even legal characters support it's java identifier i'd steer clear http//replaced.url. kinda late party interesting thread i'm wondering anyone using solrcloud hdfs large scales really like capability since data inside hadoop run solr shards nodes need manage metal although cluster actually nodes run typical query takes seconds run faceting clustering minute range depends queried little seconds index contains fields looking switching different method indexing data involve much larger number fields little stored index index help improve performance i've used shardsplit success server split needs triple amount direct memory using hdfs node needs three x amount running three shards lead it'swap you're careful large indexes split long time run much longer rest timeout monitored checking zookeeper it's clusterstate.json. first starting play dataimporthandler dih cool rather simple case indexing rss feed contains articles articles entry database contains url article rating config appended db looks like rss feed comes blog heh it's convenient control question let it's say initial set ratings feed full import articles feed everything peachy far get new rating existing article i've already indexed thus child entity named delta however run delta-import wouldn't pick changes since believe parent wouldn't changed either something wrong seems like akin parentdeltaquery problem course parent query since parent table db sense least see relevant logs case handled suggestions alternatives help would appreciated thanks. hmm i've seen bug like wouldn't think would tickled replicating config files def looks related though i'll try around next time happens look slave files index slave plain 'index timestamp part timestamp.index. hi lot posts talk hardening /admin handler user credentials etc hardened considering fact could allow secure external access admin interface allow proper cluster work setting security admin/cores option thanks. errors persist complete index rebuild wouldn't done extensive checks far index seems work correctly need concerned thanks. hi noticed use removeduplicatestokenfilter query time consider term positions really anything e.g query 'term term term far see term positions make difference simple non-phrase search built-in way deal know write filter feel like would something quite basic query wouldn't think it's even anything weird normal users consider e.g searching music verified least according anecdotal evicende search really slows repeat term enough. thanks yes makes sense i'll experimenting along lines hitcollector solr standalone programs well yield meaningful resolution would benefit community it's interest i'll concept patch mentioned. could create list field might well create add fields schema.xml original point able refer field username string define explicitly solr reread schema file post add action starup solr reads schema.xml file indexschema object builds schema.xml used pervasively document adds searches understand use field general wonder adding suffix dynamic fields posing think user programmer it's intuitive think integer therefore enter searching think it's definitely tradeoff dynamic fields make easy add arbitrary fields information infered naming convention use names cleaner names create explict fields advance. defaulting behavior since forever changing behavior going happen making fit new version correct change behavior every application specified default behavior it's a-priori reason expect words equal fewer docs easily argue words return docs expect depends mental model providing default request handlers allows implement whatever model application chooses best replaced email.addr.es wrote. would use bq parameter boost question_source==0 documents first similar. look http//replaced.url it's pretty decent explanation memory mapped files wouldn't believe default configuration solr use mmapdirectory even understanding entire file wouldn't forcibly cached solr it's filesystem cache control it's actually ram eviction process depend thanks. pierce commented thrift-0. general comment speaking viewpoint hbase committer phoenix never deploy not-released rc code production setting upgrade path official-version-x official-version-y version-0/0/0 version-x-rc official-version-y james mentioned things may change really stable official versions although rc probably safe anyway i'll likely sorry bit rant unreleased software rcs meant production author lhofhansl general comment speaking viewpoint hbase committer phoenix never deploy not-released rc code production setting upgrade path official-version-x official-version-y version-0/0/0 version-x-rc official-version-y james mentioned things may change really stable official versions although rc probably safe anyway i'll likely sorry bit rant unreleased software rcs meant production. kafka-0 improve simpleconsumershell max messages config option kafka-0 controlled shutdown don't seem work broker cluster kafka-0 kafka broker give better error message running zookeeper kafka-0 error messages logged failing-to-send messages producer kafka-0 using chroot path create chroot startup don't exist kafka-0 seems show less performance kafka-0 subsequent calls consumerconnector.createmessagestreams cause consumer offset incorrect may edit subscription. using propertyshadowbuilder build service property null immediate exception needed rather nullpointerexception. new replication command needed force backup committed index data email describing problem possible solution agree think options could useful perhaps 'forcebackup well documentation would rest added info wiki yet http//replaced.url. don't reliably kill oozie jobs mostly fails occasionally succeeds kill fails oozie server restart usually fixes issue job killed shutdown/startup sequence hangs forever occasionally exits command error cmd line several errors oozie log find following errors logs tain object lock null caused org.apache.openjpa.persistence.optimisticlockexception unable obtain object lock null caused java.sql.sqltransactionrollbackexception lock could obtained within time requested caused java.sql.sqlexception lock could obtained within time requested caused error 00xl0 lock could obtained within time requested. long time still thank work
